{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3c4fjZwC4T"
      },
      "source": [
        "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2JdzEXmwRU5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8iHXIVwDwj"
      },
      "source": [
        "***Some parts of the notebook are almost the copy of [ mmta-team course](https://github.com/mmta-team/mmta_fall_2020). Special thanks to mmta-team for making them publicly available. [Original notebook](https://github.com/mmta-team/mmta_fall_2020/blob/master/tasks/01_word_embeddings/task_word_embeddings.ipynb).***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D0wm5jt6j0U"
      },
      "source": [
        "<b> Прочитайте семинар, пожалуйста, для успешного выполнения домашнего задания. В конце ноутка напишите свой вывод. Работа без вывода оценивается ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIWqBuEa6j0b"
      },
      "source": [
        "## Задача поиска схожих по смыслу предложений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUkwMPLA6j0g"
      },
      "source": [
        "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNRXIEfu5a3Q"
      },
      "source": [
        "До этого в курсе не было речи про задачу ранжировния, поэтому введем математическую формулировку"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS9FwWNd5a3S"
      },
      "source": [
        "## Задача ранжирования(Learning to Rank)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwY9-f75a3T"
      },
      "source": [
        "* $X$ - множество объектов\n",
        "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
        "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
        "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
        "### Задача:\n",
        "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
        "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG2IGBsh5a3U"
      },
      "source": [
        "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQk_rolFwT_h"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUe1PGXn6j0l"
      },
      "source": [
        "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
        "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYkI54Y-rk7a",
        "outputId": "d5f78863-2677-468c-a6e4-1fe503a58af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-09-30 13:41:03--  https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1199620/files/SO_vectors_200.bin [following]\n",
            "--2025-09-30 13:41:03--  https://zenodo.org/records/1199620/files/SO_vectors_200.bin\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1453905423 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘SO_vectors_200.bin?download=1’\n",
            "\n",
            "SO_vectors_200.bin? 100%[===================>]   1.35G  1.70MB/s    in 15m 40s \n",
            "\n",
            "2025-09-30 13:56:44 (1.47 MB/s) - ‘SO_vectors_200.bin?download=1’ saved [1453905423/1453905423]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKnj37A9A-2C",
        "outputId": "a375135a-795d-40c8-ff56-338f7f828f32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.12/site-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (5.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O8YJTOYv6j0s"
      },
      "outputs": [],
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin_download=1\", binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIcT_g-C6j1E"
      },
      "source": [
        "#### Как пользоваться этими векторами?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWO5SPDY6j1G"
      },
      "source": [
        "Посмотрим на примере одного слова, что из себя представляет embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeSBlQfk6j1J",
        "outputId": "e486787c-03ea-42f6-f2aa-557b5e3185ae",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float32 (200,)\n"
          ]
        }
      ],
      "source": [
        "word = 'dog'\n",
        "if word in wv_embeddings:\n",
        "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Eq-D1qxpMJ",
        "outputId": "4397a97e-45bc-4eed-86c2-8ce3763df027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of words: 1787145\n"
          ]
        }
      ],
      "source": [
        "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6NTCys6j1Q"
      },
      "source": [
        "Найдем наиболее близкие слова к слову `dog`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n08z2PjMwC5o"
      },
      "source": [
        "#### ***Вопрос 1:***\n",
        "* Входит ли слово `cat` в топ-5 близких слов к слову `dog`? Какое место оно занимает?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYwVz0xG6j1U",
        "outputId": "f3d4abc1-70ad-47f2-ac9f-2531744c54be",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('animal', 0.8564179539680481), ('dogs', 0.7880867123603821), ('mammal', 0.7623804211616516), ('cats', 0.7621253728866577), ('animals', 0.7607938647270203)]\n"
          ]
        }
      ],
      "source": [
        "# method most_simmilar\n",
        "word = \"dog\"\n",
        "top5 = wv_embeddings.most_similar(word, topn=5)\n",
        "print(top5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFYgMNgsCJKU",
        "outputId": "f3cf1f6a-7037-4226-d175-0b29914e7fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity(dog, cat) = 0.6852\n",
            "[0.07585394 0.21143065 0.00233965 ... 0.16834745 0.03601661 0.05869402]\n",
            "[   3880    4323    9942 ... 1191840    2882    4971]\n",
            "Позиция cat в списке ближайших к dog: 27\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "word1, word2 = \"dog\", \"cat\"\n",
        "\n",
        "# мера сходства\n",
        "sim = wv_embeddings.similarity(word1, word2)\n",
        "print(f\"Cosine similarity({word1}, {word2}) = {sim:.4f}\")\n",
        "\n",
        "# Берём вектор первого слова\n",
        "vec = wv_embeddings[word1]\n",
        "\n",
        "# Считаем косинусное сходство word1 со всеми словами одним векторным умножением\n",
        "sims = np.dot(wv_embeddings.vectors, vec) / (\n",
        "    norm(wv_embeddings.vectors, axis=1) * norm(vec)\n",
        ")\n",
        "print(sims)\n",
        "\n",
        "# Сортируем индексы слов по убыванию близости\n",
        "ranking = np.argsort(-sims)\n",
        "print(ranking)\n",
        "\n",
        "# Находим позицию word2 в этом рейтинге\n",
        "rank_position = np.where(ranking == wv_embeddings.key_to_index[word2])[0][0] + 1\n",
        "\n",
        "print(f\"Позиция {word2} в списке ближайших к {word1}: {rank_position}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wu7O43AY5jH"
      },
      "source": [
        "***Ответ:*** 'cat' не входит в топ-5 ближайших слов к 'dog'. 'cat' находится на 27 месте"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai48-5vv6j1d"
      },
      "source": [
        "### Векторные представления текста\n",
        "\n",
        "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/nikitacernov/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/nikitacernov/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhNuxBJd6j1f",
        "outputId": "c4d80bb6-0ae0-4fc2-8e86-98359f59d111"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\w'\n",
            "/var/folders/yr/s_88h1jx275_s5hfylyqqmxc0000gn/T/ipykernel_36433/3959054116.py:12: SyntaxWarning: invalid escape sequence '\\w'\n",
            "  tokens = re.findall('\\w+', text.lower())\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = WordPunctTokenizer()\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "    def tokenize(self, text, tokenizer, lemm=True):\n",
        "      if tokenizer == 're':\n",
        "        tokens = re.findall('\\w+', text.lower())\n",
        "      elif tokenizer == 'WordPunctTokenizer':\n",
        "        tokens = self.tokenizer.tokenize(text.lower())\n",
        "      if lemm:\n",
        "         tokens = [self.lemmatizer.lemmatize(t) for t in tokens]\n",
        "      return tokens\n",
        "         \n",
        "tokenizer = MyTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nmFbT-BJiE_",
        "outputId": "ad16c0aa-603d-42e6-fb91-81696adcb7d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['размер', 'любого', 'вектора', 'в', 'нашем', 'представлении']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss = 'I love neural networks'\n",
        "ss = 'размер любого вектора в нашем представлении'\n",
        "tokens = tokenizer.tokenize(ss, 'WordPunctTokenizer')\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnK7t3pMKiye",
        "outputId": "38067d7b-eb11-4119-c43c-bc6dd6f19510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "vectors = []\n",
        "count = 0\n",
        "for word in tokens:\n",
        "  if word in wv_embeddings:\n",
        "      vectors.append(wv_embeddings[word])\n",
        "      count+=1\n",
        "\n",
        "if count == 0:\n",
        "  mean_vec = np.zeros(200)\n",
        "else:\n",
        "  mean_vec = np.mean(vectors, axis=0)  # shape будет (200,)\n",
        "\n",
        "print(mean_vec.shape, mean_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHcvu6186j1m"
      },
      "outputs": [],
      "source": [
        "def question_to_vec(question, embeddings, tokenizer, dim=200):\n",
        "    \"\"\"\n",
        "        question: строка\n",
        "        embeddings: наше векторное представление\n",
        "        dim: размер любого вектора в нашем представлении\n",
        "\n",
        "        return: векторное представление для вопроса\n",
        "    \"\"\"\n",
        "\n",
        "    tokens = tokenizer.tokenize(question, 're')\n",
        "    vectors = []\n",
        "    count = 0\n",
        "\n",
        "    for word in tokens:\n",
        "      if word in embeddings:\n",
        "          vectors.append(embeddings[word])\n",
        "          count+=1\n",
        "\n",
        "    if count == 0:\n",
        "      mean_vec = np.zeros(dim)\n",
        "    else:\n",
        "      mean_vec = np.mean(vectors, axis=0)\n",
        "\n",
        "    return mean_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Q_4j7r6j1u"
      },
      "source": [
        "Теперь у нас есть метод для создания векторного представления любого предложения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsJSNkhm6j1y"
      },
      "source": [
        "#### ***Вопрос 2:***\n",
        "\n",
        "* Какая третья (с индексом 2) компонента вектора предложения `I love neural networks` (округлите до 2 знаков после запятой)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a62r11cT6j10",
        "outputId": "0588a49c-0db6-4f98-9371-e5765642dcb2",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1.29"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Предложение\n",
        "question = \"I love neural networks\"\n",
        "\n",
        "question_to_vec(question, wv_embeddings, tokenizer)[2].round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y60z4t6W6j16"
      },
      "source": [
        "### Оценка близости текстов\n",
        "\n",
        "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями.\n",
        "\n",
        "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
        "\n",
        "#### Hits@K\n",
        "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
        "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
        "* $\\begin{equation*}\n",
        "[x < 0 ] \\equiv\n",
        " \\begin{cases}\n",
        "   1, &x < 0\\\\\n",
        "   0, &x \\geq 0\n",
        " \\end{cases}\n",
        "\\end{equation*}$ - индикаторная функция\n",
        "* $q_i$ - $i$-ый вопрос\n",
        "* $q_i^{'}$ - его дубликат\n",
        "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
        "\n",
        "Hits@K  измеряет долю вопросов, для которых правильный ответ попал в топ-K позиций среди отранжированных кандидатов.\n",
        "\n",
        "#### DCG@K\n",
        "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
        "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
        "С такой метрикой модель штрафуется за большой ранк корректного ответа.\n",
        "\n",
        "DCG@K  измеряет качество ранжирования, учитывая не только факт наличия правильного ответа в топ-K, но и ***его точную позицию***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tFemBkP6j1-"
      },
      "source": [
        "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sUSxk866j1_"
      },
      "source": [
        "#### Пример оценок\n",
        "\n",
        "Вычислим описанные выше метрики для игрушечного примера.\n",
        "Пусть\n",
        "* $N = 1$, $R = 3$\n",
        "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
        "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
        "\n",
        "Пусть модель выдала следующий ранжированный список кандидатов:\n",
        "\n",
        "1. \"Как изучить с++?\"\n",
        "2. <font color='red'>\"Что такое язык python?\"</font>\n",
        "3. \"Хочу учить Java\"\n",
        "4. \"Не понимаю Tensorflow\"\n",
        "\n",
        "$\\Rightarrow rank\\_q_i^{'} = 2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XXCbN3uUiHU"
      },
      "source": [
        "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
        "\n",
        "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1]$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_1} \\leq 1 $: ***условие неверно***.\n",
        "\n",
        "Следовательно, $[\\text{rank}_{q'_1} \\leq 1] = 0$.\n",
        "\n",
        "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_1} \\leq 4 $: ***условие верно***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya9gf-dvVGmm"
      },
      "source": [
        "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
        "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
        "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4L6HJJC6j2B"
      },
      "source": [
        "#### ***Вопрос 3***:\n",
        "* Вычислите `DCG@10`, если $rank\\_q_i^{'} = 9$(округлите до одного знака после запятой)\n",
        "#### ***Ответ:***\n",
        "* [K = 10] $\\text{DCG@10} = \\frac{1}{\\log_2(1+9)}\\cdot[9 \\le 10] = \\frac{1}{\\log_2{10}} = 0.3$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1PtUq3haNS"
      },
      "source": [
        "#### Более сложный пример оценок\n",
        "\n",
        "Рассмотрим пример с $ N > 1 $, где $ N = 3 $ (три вопроса) и для каждого вопроса заданы позиции их дубликатов. Вычислим метрики **Hits@K** для разных значений $ K $.\n",
        "\n",
        "---\n",
        "\n",
        "- $ N = 3 $: Три вопроса ($ q_1, q_2, q_3 $).\n",
        "- Для каждого вопроса известна позиция его дубликата ($ \\text{rank}_{q'_i} $):\n",
        "  - $ \\text{rank}_{q'_1} = 2 $,\n",
        "  - $ \\text{rank}_{q'_2} = 5 $,\n",
        "  - $ \\text{rank}_{q'_3} = 1 $.\n",
        "\n",
        "Мы будем вычислять **Hits@K** для $ K = 1, 5 $.\n",
        "\n",
        "---\n",
        "\n",
        "**Для $ K = 1 $:**\n",
        "\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{Hits@1} = \\frac{1}{3} \\cdot \\left( [\\text{rank}_{q'_1} \\leq 1] + [\\text{rank}_{q'_2} \\leq 1] + [\\text{rank}_{q'_3} \\leq 1] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 1 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 1 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{Hits@1} = \\frac{1}{3} \\cdot (0 + 0 + 1) = \\frac{1}{3}.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{Hits@1} = \\frac{1}{3}}.\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "**Для $ K = 5 $:**\n",
        "\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{Hits@5} = \\frac{1}{3} \\cdot \\left( [\\text{rank}_{q'_1} \\leq 5] + [\\text{rank}_{q'_2} \\leq 5] + [\\text{rank}_{q'_3} \\leq 5] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 5 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 5 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{Hits@5} = \\frac{1}{3} \\cdot (1 + 1 + 1) = 1.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{Hits@5} = 1}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngfvO7JsqROf"
      },
      "source": [
        "Теперь вычислим метрику **DCG@K** для того же примера, где $ N = 3 $ (три вопроса), и для каждого вопроса известна позиция его дубликата ($ \\text{rank}_{q'_i} $):\n",
        "\n",
        "- $ \\text{rank}_{q'_1} = 2 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $.\n",
        "\n",
        "Мы будем вычислять **DCG@K** для $ K = 1, 5 $.\n",
        "\n",
        "---\n",
        "**Для $ K = 1 $:**\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{DCG@1} = \\frac{1}{3} \\cdot \\left( \\frac{1}{\\log_2(1 + \\text{rank}_{q'_1})} \\cdot [\\text{rank}_{q'_1} \\leq 1] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_2})} \\cdot [\\text{rank}_{q'_2} \\leq 1] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_3})} \\cdot [\\text{rank}_{q'_3} \\leq 1] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 1 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 1 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{DCG@1} = \\frac{1}{3} \\cdot (0 + 0 + 1) = \\frac{1}{3}.\n",
        "$$\n",
        "$$\n",
        "\\boxed{\\text{DCG@1} = \\frac{1}{3}}.\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Для $ K = 5 $:**\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{DCG@5} = \\frac{1}{3} \\cdot \\left( \\frac{1}{\\log_2(1 + \\text{rank}_{q'_1})} \\cdot [\\text{rank}_{q'_1} \\leq 5] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_2})} \\cdot [\\text{rank}_{q'_2} \\leq 5] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_3})} \\cdot [\\text{rank}_{q'_3} \\leq 5] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 5 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 5 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{DCG@5} = \\frac{1}{3} \\cdot (0.631 + 0.387 + 1) = \\frac{1}{3} \\cdot 2.018 \\approx 0.673.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{DCG@5} \\approx 0.673}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHCnH-jw6j18"
      },
      "source": [
        "#### ***Вопрос 4:***\n",
        "* Найдите максимум `Hits@47 - DCG@1`?\n",
        "\n",
        "#### ***Ответ:***\n",
        "* `Hits@47`\n",
        "  - Максимум будет 1, если документ стоит на позиции от 1 до 47.\n",
        "* `DCG@1`\n",
        "  - Минимум будет 0, если документ стоит на позиции больше, чем 1.\n",
        "* Максимум `Hits@47 - DCG@1`\n",
        "  - Пример ситуации для максимума: релевантный документ есть в топ-47, но он стоит, скажем, на позиции 10 (первый результат нерелевантен). Тогда Hits@47=1, DCG@1=0, разница = 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5xWOORI6j2F"
      },
      "source": [
        "### HITS\\_COUNT и DCG\\_SCORE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1q9WQOx6j2H"
      },
      "source": [
        "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$.\n",
        "\n",
        "$dup\\_ranks$ является списком, который содержит рейтинги дубликатов (их позиции в ранжированном списке).\n",
        "\n",
        "К примеру для <font color='red'>\"Что такое язык python?\"</font> $dup\\_ranks = [2]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F5VwySUB6j2J"
      },
      "outputs": [],
      "source": [
        "def hits_count(dup_ranks, k):\n",
        "    \"\"\"\n",
        "        dup_ranks: list индексов дубликатов\n",
        "        k: пороговое значение для ранга\n",
        "        result: вернуть Hits@k\n",
        "    \"\"\"\n",
        "    # Подсчитываем количество дубликатов, чей ранг <= k\n",
        "    hits_value = 0\n",
        "    for dupl_pos in dup_ranks:\n",
        "      if dupl_pos <= k:\n",
        "        hits_value+=1\n",
        "    return hits_value/len(dup_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSjm_5eWYVYI",
        "outputId": "9209b8d1-5cfb-437f-dc7d-d1a1b5f2614a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hits@1 = 0.0\n",
            "Hits@4 = 1.0\n"
          ]
        }
      ],
      "source": [
        "dup_ranks = [2]\n",
        "\n",
        "k = 1\n",
        "hits_value = hits_count(dup_ranks, k)\n",
        "print(f\"Hits@1 = {hits_value}\")\n",
        "\n",
        "k = 4\n",
        "hits_value = hits_count(dup_ranks, k)\n",
        "print(f\"Hits@4 = {hits_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "82hQaxCH6j2R"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def dcg_score(dup_ranks, k):\n",
        "    \"\"\"\n",
        "        dup_ranks: list индексов дубликатов\n",
        "        k: пороговое значение для ранга\n",
        "        result: вернуть DCG@k\n",
        "    \"\"\"\n",
        "    # Вычисляем сумму для всех релевантных дубликатов\n",
        "    sum_value = 0\n",
        "    for dupl_pos in dup_ranks:\n",
        "      if dupl_pos <= k:\n",
        "        sum_value += 1 / math.log2(dupl_pos + 1)\n",
        "\n",
        "    return sum_value/len(dup_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJYsEdx-amB4",
        "outputId": "9b9119e1-323c-4ddf-bbe8-74d3665f56a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@1 = 0.000\n",
            "DCG@10 = 0.631\n"
          ]
        }
      ],
      "source": [
        "# Пример списка позиций дубликатов\n",
        "dup_ranks = [2]\n",
        "\n",
        "# Вычисляем DCG@1\n",
        "dcg_value = dcg_score(dup_ranks, k=1)\n",
        "print(f\"DCG@1 = {dcg_value:.3f}\")\n",
        "\n",
        "# Вычисляем DCG@4\n",
        "dcg_value = dcg_score(dup_ranks, k=4)\n",
        "print(f\"DCG@10 = {dcg_value:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcwHeXN26j2Y"
      },
      "source": [
        "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fjISmOEW6j2h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLa_Wqfh6j2m",
        "outputId": "7b7194a6-c57f-4f7d-ac07-2ff1d31d2fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
            "Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
          ]
        }
      ],
      "source": [
        "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
        "\n",
        "# наши кандидаты\n",
        "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
        "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
        "                       \"NSLog array description not memory address\",\n",
        "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
        "\n",
        "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
        "dup_ranks = [2]\n",
        "\n",
        "# вычисляем метрику для разных k\n",
        "print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
        "print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoHC3YoQ6j2t"
      },
      "source": [
        "У вас должно получиться"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "B0NFWq4f6j2u",
        "outputId": "4d70f590-9924-4b50-d400-cdbf43edf093",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HITS</th>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DCG</th>\n",
              "      <td>0</td>\n",
              "      <td>0.63093</td>\n",
              "      <td>0.63093</td>\n",
              "      <td>0.63093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      1        2        3        4\n",
              "HITS  0  1.00000  1.00000  1.00000\n",
              "DCG   0  0.63093  0.63093  0.63093"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# correct_answers - метрика для разных k\n",
        "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
        "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
        "correct_answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHZqgDTo6j0i"
      },
      "source": [
        "### Данные\n",
        "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
        "\n",
        "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
        "\n",
        "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKVK2lDGvrIe",
        "outputId": "cbcc23e2-7fe9-4e32-ae1a-e8d6b33ad019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  stackoverflow_similar_questions.zip\n",
            "   creating: data/\n",
            "  inflating: data/.DS_Store          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "  inflating: data/train.tsv          \n",
            "  inflating: data/validation.tsv     \n"
          ]
        }
      ],
      "source": [
        "!unzip stackoverflow_similar_questions.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hil2UsUG6j22"
      },
      "source": [
        "Считайте данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B4EBho8s6j26"
      },
      "outputs": [],
      "source": [
        "def read_corpus(filename):\n",
        "    data = []\n",
        "    with open(filename, encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            data.append(line.strip().split('\\t'))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkTxY3Mk9_nG"
      },
      "source": [
        "Нам понадобиться только файл validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PTVB9Tnp6j29"
      },
      "outputs": [],
      "source": [
        "validation_data = read_corpus('./data/validation.tsv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTHfL-9y6j3F"
      },
      "source": [
        "Кол-во строк"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6ubXhIe6j3H",
        "outputId": "0d737131-796d-4a84-801a-e54057c8f1ac",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3760"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaOQblBy6j3M"
      },
      "source": [
        "Размер нескольких первых строк"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRx6e-Pe6j3M",
        "outputId": "9ecbd430-51b0-4a07-a3c9-4121a5fdecf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 1001\n",
            "2 1001\n",
            "3 1001\n",
            "4 1001\n",
            "5 1001\n",
            "6 1001\n",
            "7 1001\n",
            "8 1001\n",
            "9 1001\n",
            "10 1001\n",
            "11 1001\n",
            "12 1001\n",
            "13 1001\n",
            "14 1001\n",
            "15 1001\n",
            "16 1001\n",
            "17 1001\n",
            "18 1001\n",
            "19 1001\n",
            "20 1001\n",
            "21 1001\n",
            "22 1001\n",
            "23 1001\n",
            "24 1001\n",
            "25 1001\n"
          ]
        }
      ],
      "source": [
        "for i in range(25):\n",
        "    print(i + 1, len(validation_data[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQQp0oQt1Ep"
      },
      "source": [
        "### Ранжирование без обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iElEDhj-6j3R"
      },
      "source": [
        "Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K02JARKr6j3T"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "1yP8wJWj6j3X"
      },
      "outputs": [],
      "source": [
        "def rank_candidates(question, candidates, embeddings, tokenizer, dim=200):\n",
        "    \"\"\"\n",
        "        question: строка\n",
        "        candidates: массив строк(кандидатов) [a, b, c]\n",
        "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
        "    \"\"\"\n",
        "\n",
        "    cand_vec = []\n",
        "    for i in range(len(candidates)):\n",
        "      cand_vec.append(question_to_vec(candidates[i], embeddings, tokenizer))\n",
        "\n",
        "    quest_vec = question_to_vec(question, embeddings, tokenizer)\n",
        "    sim_score = [cosine_similarity(quest_vec.reshape(1, -1), cand_vec[i].reshape(1, -1))[0][0] for i in range(len(cand_vec))]\n",
        "    # sorted_pairs = sorted(zip(sim_score, candidates), key=lambda x: x[0], reverse=True) # x[0] «сортируй по первому элементу кортежа (т.е. по score)».\n",
        "    indexed = list(enumerate(zip(sim_score, candidates)))\n",
        "    sorted_pairs = sorted(indexed, key=lambda x: x[1][0], reverse=True)\n",
        "\n",
        "    return sorted_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "iB6i8AoD2niz"
      },
      "outputs": [],
      "source": [
        "# cand_vec = []\n",
        "# for i in range(len(candidates[0])):\n",
        "#  cand_vec.append(question_to_vec(candidates[0][i], wv_embeddings, tokenizer))\n",
        "\n",
        "# quest_vec = question_to_vec(questions[0], wv_embeddings, tokenizer)\n",
        "\n",
        "# sim_score = [cosine_similarity(quest_vec.reshape(1, -1), cand_vec[i].reshape(1, -1))[0][0] for i in range(len(cand_vec))]\n",
        "\n",
        "# sorted_pairs = sorted(zip(sim_score, candidates[0]), key=lambda x: x[0], reverse=True) # x[0] «сортируй по первому элементу кортежа (т.е. по score)».\n",
        "# indexed = list(enumerate(zip(sim_score, candidates[0])))\n",
        "# print(sorted_pairs)\n",
        "# print(indexed)\n",
        "# # сортируем по score (берём элемент [1][0])\n",
        "# sorted_pairs = sorted(indexed, key=lambda x: x[1][0], reverse=True)\n",
        "# print(sorted_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnBszTb76j3c"
      },
      "source": [
        "Протестируйте работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xvQgtP176j3h"
      },
      "outputs": [],
      "source": [
        "questions = ['converting string to list', 'Sending array via Ajax fails']\n",
        "\n",
        "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
        "               'C# create cookie from string and send it',\n",
        "               'How to use jQuery AJAX for an outside domain?'],\n",
        "\n",
        "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
        "               'WPF- How to update the changes in list item of a list',\n",
        "               'select2 not displaying search results']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPj1JGFi6j3m",
        "outputId": "85198eca-f04b-4ab1-c05c-d80eb59f4fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "converting string to list\n",
            "[(1, (0.5922089, 'C# create cookie from string and send it')), (0, (0.5414996, 'Convert Google results object (pure js) to Python object')), (2, (0.097037084, 'How to use jQuery AJAX for an outside domain?'))]\n",
            "\n",
            "Sending array via Ajax fails\n",
            "[(0, (0.4613238, 'Getting all list items of an unordered list in PHP')), (2, (0.32301265, 'select2 not displaying search results')), (1, (0.3005938, 'WPF- How to update the changes in list item of a list'))]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for question, q_candidates in zip(questions, candidates):\n",
        "        ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer)\n",
        "        print(question)\n",
        "        print(ranks)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm4cidj56j3q"
      },
      "source": [
        "Для первого экперимента вы можете полностью сравнить ваши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0LeKMIsn6j3s"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "Invalid star expression (1724534416.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    [(*, 'Getting all list items of an unordered list in PHP'), #скрыт\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Invalid star expression\n"
          ]
        }
      ],
      "source": [
        "# должно вывести\n",
        "results = [[(1, 'C# create cookie from string and send it'),\n",
        "            (0, 'Convert Google results object (pure js) to Python object'),\n",
        "            (2, 'How to use jQuery AJAX for an outside domain?')],\n",
        "           [(*, 'Getting all list items of an unordered list in PHP'), #скрыт\n",
        "            (*, 'select2 not displaying search results'), #скрыт\n",
        "            (*, 'WPF- How to update the changes in list item of a list')]] #скрыт"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ttnIBe6j3x"
      },
      "source": [
        "Последовательность начальных индексов вы должны получить `для эксперимента 1`  1, 0, 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQgYDWd6j3y"
      },
      "source": [
        "#### ***Вопрос 5:***\n",
        "* Какую последовательность начальных индексов вы получили `для эксперимента 2`(перечисление без запятой и пробелов, например, `102` для первого эксперимента?\n",
        "#### ***Ответ***\n",
        "* `021`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPllOY-Y6j30"
      },
      "source": [
        "Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Можете взять для validation 1000 примеров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z3q9sxddz-yU"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9c806407819b425d8d7c900910696838",
            "7d437cce860b4402b723d14d73f92b1c",
            "aa72a06b06da471b953a086c27f4422b",
            "64a2b3eeb7644add97fbd15bf7400993",
            "394f9182fccf4f248c130a60db69a4ef",
            "93f77c977105413eadfbe7c1c6453cad",
            "ba5b3b06e13d4c2997028de0fae56dd8",
            "3b1cb891f3e74f76a0339e498ebc0278",
            "551ace5c3d1d4393b84837f5c38306a3",
            "da2b2da821914dd3bcadd15d2cfa77e0",
            "3a374e67d8244ad9b6a79bfce057b3cb"
          ]
        },
        "id": "nu7K4mis6j32",
        "outputId": "d3280a22-d92b-42ee-d216-4df73de3ae2b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dd1c0dc55da4f889d2445211bd3c032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3760 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    # if i == max_validation_examples:\n",
        "    #     break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, wv_embeddings, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "b17405c6375a4bbc8fbb9f9fb341186e",
            "040233a0ce524e8abfd1fb6e3f498136",
            "664296f75b1a49c29bfc5719de84a27e",
            "e17bce3307b440528666c7002109465c",
            "97b15376fcfa4b8db2fb64a26f31c4a4",
            "9b55448c176c4c0d9753a978616ddcbd",
            "c65a4a59ca7f4a7e9a4ed35e34ba7076",
            "cb0ca0c230ea4e0f8c1356b1cd5ff516",
            "60888c1e918644308c5407385d182267",
            "4d6bc4c07bf44ea388f0b9846636acdc",
            "794205e1ac1746b5a57e4782a8d09152"
          ]
        },
        "id": "gDtS520v6j35",
        "outputId": "584203a8-7b0e-4734-ea0b-112ee7e411a1",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a6fb3bc64c04be7bdfc778ac33090b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.412 | Hits@   1: 0.412\n",
            "DCG@   5: 0.500 | Hits@   5: 0.579\n",
            "DCG@  10: 0.525 | Hits@  10: 0.656\n",
            "DCG@ 100: 0.570 | Hits@ 100: 0.874\n",
            "DCG@ 500: 0.584 | Hits@ 500: 0.976\n",
            "DCG@1000: 0.586 | Hits@1000: 1.000\n"
          ]
        }
      ],
      "source": [
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ16fNZ4mxTC"
      },
      "source": [
        "Из формул выше можно понять, что\n",
        "\n",
        "- $ \\text{Hits@K} $ **монотонно неубывающая функция** $ K $, которая стремится к 1 при $ K \\to \\infty $.\n",
        "\n",
        "- $ \\text{DCG@K} $ **монотонно неубывающая функция** $ K $, но рост замедляется с увеличением $ K $ из-за убывания веса $ \\frac{1}{\\log_2(1 + \\text{rank}_{q'_i})} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL6_Rjg3InL8"
      },
      "source": [
        "### Эмбеддинги, обученные на корпусе похожих вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iNvbpR5gJIPz"
      },
      "outputs": [],
      "source": [
        "train_data = read_corpus('./data/train.tsv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr281ZyEJfjT"
      },
      "source": [
        "Улучшите качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберите размер window. Объясните свой выбор.\n",
        "\n",
        "***Рассмотрим подробнее*** данное склеивание.\n",
        "\n",
        "1. Каждая строка из train_data разбивается на вопрос (question) и список кандидатов.\n",
        "\n",
        "2. Для каждого кандидата вопрос склеивается с ним в одну строку.\n",
        "\n",
        "3. Склеенная строка (combined_text) токенизируется, и полученный список токенов добавляется в общий корпус (corpus).\n",
        "\n",
        "***Пример***\n",
        "\n",
        "    Вопрос: \"What is Python?\"\n",
        "    Кандидаты: [\"Python is a programming language\", \"Java is another language\"]\n",
        "    Склеенные строки:\n",
        "        \"What is Python? Python is a programming language\"\n",
        "        \"What is Python? Java is another language\"\n",
        "         \n",
        "    Токенизированные списки:\n",
        "        ['what', 'is', 'python', 'python', 'is', 'a', 'programming', 'language']\n",
        "        ['what', 'is', 'python', 'java', 'is', 'another', 'language']\n",
        "         \n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Adding Prototype to JavaScript Object Literal',\n",
              " 'How does JavaScript .prototype work?',\n",
              " 'Javascript not setting property of undefined in prototyped object']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Без лемматизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6Y46SSQMTL0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be1add548f0c43d7b45ccb2c3d68cca7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "1256483"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Создаем общий корпус текстов\n",
        "corpus = []\n",
        "\n",
        "for item in tqdm(train_data):\n",
        "    query, answer = item[0], item[1:]\n",
        "    # Склейка\n",
        "    pairs = [tokenizer.tokenize(f'{query} {c}', 're', False) for c in answer]\n",
        "    corpus.extend(pairs)\n",
        "    # break\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "QuJzAM0cI-UH"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "embeddings_trained = Word2Vec(\n",
        "    sentences=corpus,        # Корпус токенизированных текстов\n",
        "    vector_size=200,         # Размерность векторов\n",
        "    window=3,                # Размер окна контекста\n",
        "    min_count=3,             # Минимальная частота слов\n",
        "    workers=4                # Количество потоков\n",
        ").wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "OQonbm4nMenD"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fab01afe6f64a9696cf7b2da5143ef4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3760 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "3kahBUPGMgGR"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcacb66d1d9d4ae4876a39ca984ca003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.305 | Hits@   1: 0.305\n",
            "DCG@   5: 0.373 | Hits@   5: 0.434\n",
            "DCG@  10: 0.395 | Hits@  10: 0.504\n",
            "DCG@ 100: 0.449 | Hits@ 100: 0.766\n",
            "DCG@ 500: 0.472 | Hits@ 500: 0.943\n",
            "DCG@1000: 0.478 | Hits@1000: 1.000\n"
          ]
        }
      ],
      "source": [
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### С лемматизацией"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "776905cee6a341b695d24f633f7ec061",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99758bdd36d84c53bc5f9297678e0f1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3760 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48286774dc2646aca96ed0bfc8c1d696",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.311 | Hits@   1: 0.311\n",
            "DCG@   5: 0.380 | Hits@   5: 0.441\n",
            "DCG@  10: 0.401 | Hits@  10: 0.508\n",
            "DCG@ 100: 0.457 | Hits@ 100: 0.782\n",
            "DCG@ 500: 0.478 | Hits@ 500: 0.950\n",
            "DCG@1000: 0.484 | Hits@1000: 1.000\n"
          ]
        }
      ],
      "source": [
        "# Создаем общий корпус текстов\n",
        "corpus = []\n",
        "\n",
        "for item in tqdm(train_data):\n",
        "    query, answer = item[0], item[1:]\n",
        "    # Склейка\n",
        "    pairs = [tokenizer.tokenize(f'{query} {c}', 're', True) for c in answer]\n",
        "    corpus.extend(pairs)\n",
        "    # break\n",
        "len(corpus)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "embeddings_trained = Word2Vec(\n",
        "    sentences=corpus,        # Корпус токенизированных текстов\n",
        "    vector_size=200,         # Размерность векторов\n",
        "    window=3,                # Размер окна контекста\n",
        "    min_count=3,             # Минимальная частота слов\n",
        "    workers=4                # Количество потоков\n",
        ").wv\n",
        "\n",
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n",
        "\n",
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Намеренно плохо обучаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0e1ee8d733b4ec6b1dc31b82de27bdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3760 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c7476c86b3a4f4e8ad9cdb9c4ab477a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.899 | Hits@   1: 0.899\n",
            "DCG@   5: 0.899 | Hits@   5: 0.899\n",
            "DCG@  10: 0.899 | Hits@  10: 0.899\n",
            "DCG@ 100: 0.912 | Hits@ 100: 0.980\n",
            "DCG@ 500: 0.914 | Hits@ 500: 0.994\n",
            "DCG@1000: 0.915 | Hits@1000: 1.000\n"
          ]
        }
      ],
      "source": [
        "embeddings_trained = Word2Vec(\n",
        "    sentences=corpus[0],        # Корпус токенизированных текстов\n",
        "    vector_size=200,         # Размерность векторов\n",
        "    window=3,                # Размер окна контекста\n",
        "    min_count=3,             # Минимальная частота слов\n",
        "    workers=4                # Количество потоков\n",
        ").wv\n",
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n",
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY8PxB0j-ThG"
      },
      "source": [
        "### Замечание:\n",
        "Решить эту задачу с помощью обучения полноценной нейронной сети будет вам предложено, как часть задания в одной из домашних работ по теме \"Диалоговые системы\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vymVj8IxO2PO"
      },
      "source": [
        "Напишите свой вывод о полученных результатах.\n",
        "\n",
        "## Вывод:\n",
        "* Какой принцип токенизации даёт качество лучше и почему?\n",
        "\n",
        "Практически оказалось, что токенизация с помощью re дала немного лучшее качество ранжирования.\n",
        "Причина в том, что WordPunctTokenizer создаёт слишком много редких токенов (например, \"#\", \"()\", \".\"), которые либо отсутствуют в словаре Word2Vec, либо вносят шум.\n",
        "Регулярное выражение, наоборот, сохраняет только значимые словоформы, уменьшая разреженность пространства признаков.\n",
        "\n",
        "* Помогает ли нормализация слов?\n",
        "\n",
        "Нормализация слов (в частности, приведение к нижнему регистру и лемматизация) положительно влияет на качество решения задачи.\n",
        "Без нормализации одна и та же форма слова может встречаться в корпусе под разными вариантами — например, “running”, “ran”, “runs”. Для модели Word2Vec это разные токены, и их векторные представления обучаются независимо, что приводит к “размыванию” семантики и уменьшению статистической значимости каждого слова.\n",
        "При использовании лемматизации все формы сводятся к базовой — “run”. Это увеличивает частоту встречаемости слов, улучшает устойчивость эмбеддингов и повышает качество при сравнении смыслов предложений с помощью косинусного сходства.\n",
        "В моём эксперименте нормализация дала лучшие значения метрик (Hits@k, DCG@k) по сравнению с вариантом без неё, особенно на малых k. Это объясняется тем, что модель получает более обобщённое и семантически чистое представление текстов, где схожие вопросы действительно ближе в векторном пространстве.\n",
        "\n",
        "* Какие эмбеддинги лучше справляются с задачей и почему?\n",
        "\n",
        "Для эмбедингов, обученных на базе train_data, метрики показали результаты хуже, чем на готовых stackoverflow эмбедингах.\n",
        "Это происходит потому что в большинстве случаев вектора нулевые получались, а т.к. в валидационных данных правильный ответ стоит на первом месте в списке вариантов, то в результате сортировки по косинусному расстоянию не происходит и правильный ответ сохраняет первый ранк.\n",
        "То же самое можно наблюдать, если намеренно плохо обучиться на одном предложении, в результате такого обучения у всех похожесть в результате 0 и на валидационной выборке порядок сохраняется, а там на первом месте как раз правильный вариант.\n",
        "\n",
        "* Почему получилось плохое качество решения задачи?\n",
        "\n",
        "Простая модель на усреднённых Word2Vec-векторах недостаточно выразительна для задачи семантического ранжирования вопросов. Вопросы на StackOverflow часто содержат ключевые конструкции (“convert string”, “ajax fails”), и усреднение слов теряет их смысловую структуру. В вопросах встречаются специфические токены (C#, jQuery, AJAX, JSON), которых может не быть в обученных эмбеддингах → часть предложений представляется нулевыми векторами.\n",
        "\n",
        "* Предложите свой подход к решению задачи.\n",
        "\n",
        "1. Использовать модели типа Sentence-BERT. Эти модели обучаются именно на задачах семантического сходства предложений и учитывают контекст.\n",
        "2. Добавить нормализацию и предобработку (лемматизация, фильтрация стоп-слов)\n",
        "3. Комбинировать косинусное сходство с другими метриками (например, BM25)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emODHztAQUQz"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "040233a0ce524e8abfd1fb6e3f498136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b55448c176c4c0d9753a978616ddcbd",
            "placeholder": "​",
            "style": "IPY_MODEL_c65a4a59ca7f4a7e9a4ed35e34ba7076",
            "value": "100%"
          }
        },
        "394f9182fccf4f248c130a60db69a4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a374e67d8244ad9b6a79bfce057b3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b1cb891f3e74f76a0339e498ebc0278": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6bc4c07bf44ea388f0b9846636acdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551ace5c3d1d4393b84837f5c38306a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60888c1e918644308c5407385d182267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64a2b3eeb7644add97fbd15bf7400993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2b2da821914dd3bcadd15d2cfa77e0",
            "placeholder": "​",
            "style": "IPY_MODEL_3a374e67d8244ad9b6a79bfce057b3cb",
            "value": " 1000/3760 [08:26&lt;21:41,  2.12it/s]"
          }
        },
        "664296f75b1a49c29bfc5719de84a27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0ca0c230ea4e0f8c1356b1cd5ff516",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60888c1e918644308c5407385d182267",
            "value": 6
          }
        },
        "794205e1ac1746b5a57e4782a8d09152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d437cce860b4402b723d14d73f92b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f77c977105413eadfbe7c1c6453cad",
            "placeholder": "​",
            "style": "IPY_MODEL_ba5b3b06e13d4c2997028de0fae56dd8",
            "value": " 27%"
          }
        },
        "93f77c977105413eadfbe7c1c6453cad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b15376fcfa4b8db2fb64a26f31c4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b55448c176c4c0d9753a978616ddcbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c806407819b425d8d7c900910696838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d437cce860b4402b723d14d73f92b1c",
              "IPY_MODEL_aa72a06b06da471b953a086c27f4422b",
              "IPY_MODEL_64a2b3eeb7644add97fbd15bf7400993"
            ],
            "layout": "IPY_MODEL_394f9182fccf4f248c130a60db69a4ef"
          }
        },
        "aa72a06b06da471b953a086c27f4422b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b1cb891f3e74f76a0339e498ebc0278",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_551ace5c3d1d4393b84837f5c38306a3",
            "value": 1000
          }
        },
        "b17405c6375a4bbc8fbb9f9fb341186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_040233a0ce524e8abfd1fb6e3f498136",
              "IPY_MODEL_664296f75b1a49c29bfc5719de84a27e",
              "IPY_MODEL_e17bce3307b440528666c7002109465c"
            ],
            "layout": "IPY_MODEL_97b15376fcfa4b8db2fb64a26f31c4a4"
          }
        },
        "ba5b3b06e13d4c2997028de0fae56dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c65a4a59ca7f4a7e9a4ed35e34ba7076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb0ca0c230ea4e0f8c1356b1cd5ff516": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2b2da821914dd3bcadd15d2cfa77e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17bce3307b440528666c7002109465c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6bc4c07bf44ea388f0b9846636acdc",
            "placeholder": "​",
            "style": "IPY_MODEL_794205e1ac1746b5a57e4782a8d09152",
            "value": " 6/6 [00:00&lt;00:00, 452.06it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
